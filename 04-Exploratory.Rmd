Before we perform any statistical modeling, we need to observe the data and this step is called exploratory data analysis. The exploratory phase allows us to identify patterns, detect anomalies, and verify assumptions in the data.^[<https://blog.eduonix.com/bigdata-and-hadoop/importance-exploratory-data-analysis-ml-modelling>] This is an important but often overlooked step in data analysis, and failure to explore the data can lead to inefficiencies such as accurate models on the wrong data.^[<https://towardsdatascience.com/exploratory-data-analysis-topic-that-is-neglected-in-data-science-projects-9962ae078a56>]   

Therefore, we start with examining the trends of the two main variables, **HighSchool_PR** and **College_Score**. For each variable, we observe the values and summarize them in a histogram as part of the univariate analysis. Then we investigate the relationship between the two variables, i.e., bivariate exploration.  

\section*{\textcolor{red}{Unfinished below}}  

\textcolor{red}{Removing missing values should belong in the Data Description chapter!}   

\textcolor{red}{Sensitivity analysis: Look at the univariate distribution with vs without the missing values!}      

\textcolor{red}{Basically need to explain why we used the full univariate set available, instead of just taking those with a valid second score.}     


\section*{\textcolor{red}{Unfinished below}}   


## High School Entrance Exam Scores (Percentile Rank)

We show the descriptive statistics of **HighSchool_PR** in our data, i.e., the percentile rank of high school entrance exam scores. The invalid or missing values are removed beforehand. The `summary` function returns the minimum, 1st quartile, median, mean, 3rd quartile, and maximum from the input data.   

- **Minimum**: The smallest value in the data.
- **1st Quartile**: The value where 25% of the data is below this point; that is, the middle value between the minimum and the median.
- **Median**: The value where 50% of the data is below this point, and 50% of the data is above this point.
- **Mean**: The arithmetic mean, which is calculated as the sum of the data divided by the number of the points.
- **3rd Quartile**: The value where 75% of the data is below this point; that is, the middle value between the median and the maximum.
- **Maximum**: The largest value in the data.

```{r high-school-pr}
summary(uni_HS_score)
```


**Remark**: Note that we used the full univariate set of **HighSchool_PR** available, rather than taking only those with a valid **College_Score**. The reason is that we wanted to keep as many records as possible. We can do a quick sensitivity analysis here, and the summary statistics are very similar after we exclude the few records without a valid **College_Score**.   

```{r high-school-pr-bivariate}
summary(data_corr$HighSchool_PR)
```

In the univariate analysis, the 1st quartile of **HighSchool_PR** is 85, which means only 25% of the respondents have a percentile rank (PR) below 85. Hence 75% of the respondents have a percentile rank (PR) at least 85, i.e., in the top 15% of the high school entrance exam. The median (92) is higher than the mean (89-90), indicating that the distribution is left-skewed. Half of the respondents scored **HighSchool_PR** 92 or better, and we have few samples of the lower end of the high school entrance exam. In fact, the lowest score we obtained in the data is already 51 -- still slightly above the national median score (50). The maximum is capped at 99.    

The histogram shows a left-skewed distribution, and we can see a long tail to the left. Since our data are self-reported by respondents, the ones with higher scores are more likely to report, resulting in survey non-response bias. It is also possible that many students with extremely low **HighSchool_PR** chose not to attend college, so they would not have a **College_Score** to respond to the survey.  

```{r high-school-pr-histogram}
hist(uni_HS_score, main = "Histogram of HighSchool_PR", xlab="HighSchool_PR")
```

If we were to take a sufficiently large random sample from the full database of **HighSchool_PR** in Taiwan, the minimum should be 1 and the maximum would still be at 99. However, the **HighSchool_PR** is the national percentile rank itself, so the 1st quartile should be around 25, median and mean both around 50, and the 3rd quartile around 75.   

As a baseline, we also simulate this random sample by generating data from a **discrete** uniform distribution between 1 and 99. We manually take a random sample of the same size as the univariate **HighSchool_PR** from the integers 1, 2, ..., 99, and we sample with replacement to allow duplicate values. Note that the function `runif`\footnote{The function name \texttt{runif} is pronounced as \texttt{r-unif}, not \texttt{run-if}.} in the `stats` package generates samples from the **continuous** uniform distribution, and that's why we did not use `runif` here.     

```{r gen-random-data}
possible_values = c(1:99)

set.seed(67)
# sample with replacement
random_sample = sample(possible_values, size=length(uni_HS_score), replace=TRUE)
print(random_sample)
```

As we can see, the simulated random sample has median and mean close to 50. The 1st quartile is near 25, and the 3rd quartile is near 75. The simulated sample is to demonstrate a nationally representative sample of **HighSchool_PR**. Nevertheless, this would not be appropriate for the evaluation of the relationship between **HighSchool_PR** and **College_Score**, because students with extremely low **HighSchool_PR** may decide not to attend college at all.   

```{r random-data-stats}
summary(random_sample)
```

The histogram of the simulated random sample is flat, as what we expect from a discrete uniform distribution.  

```{r random-data-histogram}
hist(random_sample, main = "Histogram of Simulated Random Sample", xlab="HighSchool_PR")
```

\section*{\textcolor{red}{Unfinished below}}   

## College Entrance Exam Scores  

Similarly, we also show the descriptive statistics of **College_Score**, i.e., the college entrance exam scores between 1 and 75. The distribution is also left-skewed, but less extreme than **HighSchool_PR**. The median of **College_Score** is 64.5, indicating that 50% of the respondents have **College_Score** 65 or higher. The 3rd quartile is already at 69, so the top score range 69-75 accounts for 25% of the respondents. This is much higher than the national average.  

```{r college-score}
summary(uni_college_score)
```

As a sensitivity analysis check, we also examine the `summary` of the **College_Score** datapoints only when they have a corresponding valid **HighSchool_PR**. The distribution is almost the same.  

```{r college-score-bivariate}
summary(data_corr$College_Score)
```

According to the reference score table^[<https://bit.ly/3bAYOvO>] from Wikipedia, the 88th percentile of the college entrance score fluctuates around 60 in Years 2004-2010, and 62-65 in Years 2011-2018. Since the median of **College_Score** is 64.5, we can infer that at least 50% of the respondents scored in the top 12% of the college entrance exam. On the other hand, the reference score table also shows that the 75th percentile of the college entrance score is between 53 and 58 in Years 2004-2018. The PTT data's 1st quantile is already at 58, so we can also infer that at least 75% of the respondents scored in the top 25% of the college entrance exam.   

Since PTT contains forums for several prestigious universities in Taiwan, it is no surprise that many users attended these colleges because they scored well on the college entrance exam. Nevertheless, PTT does not limit registration to students of these colleges, so the population of PTT is relatively diverse but still not very representative of the whole student population.   

\section*{\textcolor{red}{Unfinished below}}    

\textcolor{red}{More explanation here}   

Histogram  

```{r college-score-histogram}
hist(uni_college_score, main="Histogram of College_Score",
     xlab="College_Score (max possible is 75)",xlim=c(30,80))
```


\textcolor{red}{More explanation here}   

Emphasize that **College_Score** are not percentile ranks like **HighSchool_PR**.   

Explain why we cannot simulate a random sample for **College_Score**, even if we can obtain the five scores (88th, 75th, 50th, 25th, 12th percentile).   

Technically we can obtain the number of total students for each **College_Score** each year. Background section ?!  

## Bivariate Exploration {#bivariate}

Next, we create a bivariate scatterplot of **HighSchool_PR** and **College_Score** to examine the relationship between the two scores. Obviously, a respondent needs a valid score in both to be included in the bivariate scatterplot. Just like what we observed in the univariate plots, both variables are largely concentrated towards the maximum possible scores.   

```{r bivariate} 
plot(data_corr$HighSchool_PR, data_corr$College_Score,
     main = "High School and College Entrance Exam Scores",
     xlab="HighSchool_PR",
     ylab="College_Score")
```

The correlation coefficient is approximately 0.507, showing a medium strength of positive association between **HighSchool_PR** and **College_Score**. We can interpret that a better score in the high school entrance exam is likely to lead to a better college entrance exam score, but the relationship is not as strong after **HighSchool_PR** reaches 80.

```{r correlation}
cor(data_corr$HighSchool_PR, data_corr$College_Score)
```

To calculate the correlation coefficient between the random variables $X, Y$, we need to start with the covariance $\text{Cov}(X,Y)$ in the equation below. $E[X]$ denotes the expectation value of $X$, a.k.a. the mean of $X$.

$$\text{Cov}(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y].$$

Then we also need to compute the standard deviation $\sigma_X$:

$$\sigma_X = \sqrt{E[(X-E[X])^2]} = \sqrt{E[X^2]-(E[X])^2}.$$
Same applies to the standard deviation $\sigma_Y$.  

Finally, we can calculate the correlation coefficient as:

$$\rho_{X,Y} = \dfrac{\text{Cov}(X,Y)}{\sigma_X \sigma_Y}.$$


The correlation coefficient $\rho_{X,Y}$ is always between -1 and +1. The stronger $|\rho_{X,Y}|$ is, the stronger is the linear relationship. A positive value means the two variables $X,Y$ are positively associated with each other. In other words, when $X$ increases, $Y$ is also expected to increase. A negative value means the two variables $X,Y$ are negatively associated with each other. In this case, when $X$ increases, $Y$ is expected to decrease. The correlation coefficient may be zero, but this simply means that $X$ and $Y$ do not have a linear relationship with each other. There may exist other patterns between the two variables.  

The strength of linear relationship can be interpreted as below:^[<https://www.dummies.com/article/academics-the-arts/math/statistics/how-to-interpret-a-correlation-coefficient-r-169792>]  

- $|\rho_{X,Y}| = 1$: Perfect linear relationship

- $0.6 < |\rho_{X,Y}| < 1$: Strong linear relationship

- $0.4 < |\rho_{X,Y}| < 0.6$: Medium linear relationship

- $0.2 < |\rho_{X,Y}| < 0.4$: Low linear relationship

- $0 < |\rho_{X,Y}| < 0.2$: Little-to-no linear relationship

- $|\rho_{X,Y}| = 0$: No linear relationship

\section*{\textcolor{red}{Unfinished below}}  

Add graphical examples to show each $\rho_{X,Y}$.  

$\rho_{X,Y} = 1$ example: $y = ax+b$, with $a > 0$.  

$\rho_{X,Y} = -1$ example: $y = ax+b$, with $a < 0$.  

\textcolor{red}{Need to decide what to do with a good but imperfect linear relationship.}   

For $\rho_{X,Y} = 0$, create one graph with independence and the other graph with an obvious non-linear relationship.  

e.g. Parabola curve: $y = -x^2 + 25$, set xlim=c(-5,5)   

Graph ideas from *OpenIntro Statistics*.  
<https://github.com/OpenIntroStat/openintro-statistics/tree/master/ch_regr_simple_linear>   

\section*{\textcolor{red}{Unfinished above}}  