---
title: "PTT Analysis of Entrance Exam Scores in Taiwan"
subtitle: "A Statistical Approach with R Code"
author: "Christine P. Chai"
date: \today
output: 
        pdf_document:
                number_sections: true
                citation_package: natbib
bibliography: references.bib
biblio-style: apalike
link-citations: yes
---

\renewcommand{\cite}{\citep}

```{r latex-cite-command, include=FALSE}
# %\let\cite\citep
# % from \citep to \cite to cite in author style, e.g. [Mule, 2008]

# % \bibliographystyle{plainnat}
# %\citep: citation in parentheses, e.g. [Mule, 2008]
# %\citet: citation as author, e.g. Mule [2008]
# %\cite: citation as author, \citet by default 
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Ongoing work since 2019.

\section*{Executive Summary}

\textcolor{red}{Write something here}

# Introduction

\textcolor{red}{Consider making the introduction statistics-oriented, because we would like to focus on the statistical methodology. Most important is how to handle a real-time application problem.}  

```{r include-intro, child = '01-Introduction.Rmd'}
```

# Background

```{r include-background, child = '02-Background.Rmd'}
```

# Data Description

```{r include-data-description, child = '03-Data-Description.Rmd'}
```

# Exploratory Data Analysis

```{r include-exploratory, child = '04-Exploratory.Rmd'}
```

# Linear Regression {#linear-reg}

```{r include-linear-reg, child = '05-Linear-Regression.Rmd'}
```

# Top Scorers: A Closer Look

```{r include-linear-reg, child = '06-Top-Scorers.Rmd'}
```

# Logistic Regression {#logit-reg}

```{r include-logit-reg, child = '07-Logistic-Regression.Rmd'}
```

# Model Validation: In-Sample Prediction {#validation}

```{r include-in-sample-00, child = '08-In-Sample-00-Foreword.Rmd'}
```

## Implementation of In-Sample Prediction {#in-sample}

```{r include-in-sample-01, child = '08-In-Sample-01-Implementation.Rmd'}
```

## Interpretation of Confusion Matrix {#interpretation}

```{r include-in-sample-02, child = '08-In-Sample-02-Confusion-Matrix.Rmd'}
```

\section*{\textcolor{red}{Unfinished below}}

\textcolor{red}{Continue to separate this enormous \texttt{.Rmd} into smaller files.}

## Breakdown by High School Entrance Exam Scores

Let's examine the confusion matrices for each group of **HighSchool_PR**: 0-79, 80-89, 90-94, 95-99. Readers can refer to Section \ref{HighSchool-PR-80-up} for the details of this categorization. Before going into the analysis, we need to ensure that each group has a sufficiently large number of respondents within the 188 total records.    

The group with **HighSchool_PR** 0-79 has the smallest number of respondents, and 25 is a sufficient sample size. The groups  with **HighSchool_PR** 80-89 and 90-94 contain 49 and 44 respondents, respectively. The group with **HighSchool_PR** 95-99 includes 70 respondents, which is the largest of the four categories.  

```{r header-code,include=FALSE}
data = read.csv("ptt_SENIORHIGH_data.csv")
names(data)[1] = "pttID"

missing_rows = which(data$HighSchool_PR == "-1" | data$College_Score == "-1")
data_corr = data[-missing_rows,]

data_corr$CS_65up = data_corr$College_Score >=65

model = glm(CS_65up ~ HighSchool_PR, data=data_corr, family="binomial")

print("This is a test.")
```

```{r breakdown-by-pr}
HS0to79_ind = which(data_corr$HighSchool_PR >=0 & data_corr$HighSchool_PR <= 79)
HS80to89_ind = which(data_corr$HighSchool_PR >= 80 & data_corr$HighSchool_PR <= 89)
HS90to94_ind = which(data_corr$HighSchool_PR >= 90 & data_corr$HighSchool_PR <= 94)
HS95to99_ind = which(data_corr$HighSchool_PR >= 95 & data_corr$HighSchool_PR <= 99)

print(paste("HighSchool_PR 0-79:",length(HS0to79_ind), "respondents"))
print(paste("HighSchool_PR 80-89:",length(HS80to89_ind), "respondents"))
print(paste("HighSchool_PR 90-94:",length(HS90to94_ind), "respondents"))
print(paste("HighSchool_PR 95-99:",length(HS95to99_ind), "respondents"))
```

\section*{\textcolor{red}{Unfinished below}}    

Let's examine the confusion matrix for each of the four groups.   

- HighSchool_PR 0-79 has only FALSE predicted outcomes in **College_Score** at least 65.
- HighSchool_PR 80-89 has only FALSE predicted outcomes in **College_Score** at least 65.
- HighSchool_PR 90-94 has both TRUE and FALSE predicted outcomes in **College_Score** at least 65.
- HighSchool_PR 95-99 has only TRUE predicted outcomes in **College_Score** at least 65.  

Is the confusion matrix still valid in subsets given **HighSchool_PR**?  

Consider: Add the 2x1 confusion matrices to show why we cannot do this directly.  
Or at least explain what happened before.  

Also consider: Add a subsection for 2x1 (incorrect) and another subsection for 2x2 (correct).

```{r confusion-subset}
# UNFINISHED HERE

# Data
actual_65up = data_corr$CS_65up
# Predicted results
predicted_65up = model$fitted.values >= 0.5

confusion_subset <- function(HS_inds, actual, predicted) {
  actual = actual[HS_inds]
  predicted = predicted[HS_inds]
  confusion = table(actual, predicted)
  
  # When the confusion matrix has nonzero values in all four cells
  if ((dim(confusion)[1] == 2) && (dim(confusion)[2] == 2)) {
    # Revert the order of FALSE and TRUE
    confusion = confusion[2:1, 2:1]
    return(confusion)
  }
  
  # When all predicted values are FALSE
  else if (colnames(confusion) == c("FALSE")) {
    confusion = as.table(cbind(confusion,c(0,0)))
    colnames(confusion) = c("FALSE","TRUE")
    names(dimnames(confusion)) = c("actual","predicted")
  }
  
  # When all predicted values are TRUE
  else if (colnames(confusion) == c("TRUE")) {
    confusion = as.table(cbind(c(0,0), confusion))
    colnames(confusion) = c("FALSE","TRUE")
    names(dimnames(confusion)) = c("actual","predicted")
  }
  
  # Revert the order of FALSE and TRUE
  confusion = confusion[2:1, 2:1] 
  return(confusion)
}
```

Confusion matrix (**HighSchool_PR** 0-79 only)

```{r pr-0-79}
# UNFINISHED HERE
confusion_0to79 = confusion_subset(HS0to79_ind, actual_65up, predicted_65up)
# confusion_0to79 = confusion_0to79[2:1,1:1] # This does not work.

confusion_0to79
# Need to fix this into 2x2 matrix
```

Confusion matrix (**HighSchool_PR** 80-89 only)

```{r pr-80-89}
# UNFINISHED HERE
confusion_80to89 = confusion_subset(HS80to89_ind, actual_65up, predicted_65up)
# confusion_80to89 = confusion_0to79[2:1,1:1] # This does not work.

confusion_80to89
# Need to fix this into 2x2 matrix
```

Confusion matrix (**HighSchool_PR** 90-94 only)

```{r pr-90-94}
confusion_90to94 = confusion_subset(HS90to94_ind, actual_65up, predicted_65up)

# revert the order of FALSE and TRUE
# confusion_90to94 = confusion_90to94[2:1, 2:1]
confusion_90to94
```

Test for the other extreme: **HighSchool_PR** 95-99

```{r pr-95-99}
confusion_95to99 = confusion_subset(HS95to99_ind, actual_65up, predicted_65up)

confusion_95to99
# Need to fix this into 2x2 matrix
```


Need to finish writing up for the remaining segments.  

Most respondents with **HighSchool_PR** 95-99 got **College_Score** at least 65.   
$\Rightarrow$ Increase the cutoff point to 70?  

Need to show the breakdown like the output in Section \ref{bivariate-top-scorers}.   

But I don't think this makes sense, because **HighSchool_PR** 95-99 does not distinguish students' intellectual ability that much. 

Create more graphs  

# Model Validation: Out-of-Sample Prediction {#outsample}

```{r include-out-sample-00, child = '09-Out-Sample-00-Foreword.Rmd'}
```

## Separate Training and Testing Datasets

```{r include-out-sample-01, child = '09-Out-Sample-01-Sep-Explain.Rmd'}
```

### Implementation {#train-test-demo}

```{r include-out-sample-02, child = '09-Out-Sample-02-Sep-Implement.Rmd'}
```

### Organizing the Code for Reusability

```{r include-out-sample-03, child = '09-Out-Sample-03-Sep-Organize.Rmd'}
```

## Cross Validation

```{r include-out-sample-04, child = '09-Out-Sample-04-Cross-Validation.Rmd'}
```

### K-fold Cross Validation

```{r include-out-sample-05, child = '09-Out-Sample-05-K-Fold.Rmd'}
```

### Leave-one-out Cross Validation

```{r include-out-sample-06, child = '09-Out-Sample-06-Leave-One-Out.Rmd'}
```

## Comparison of Results

```{r include-out-sample-07, child = '09-Out-Sample-07-Comparison-Results.Rmd'}
```

# Predictive Modeling

\textcolor{red}{\Large Unfinished below}  

Use the logistic regression to predict new datapoints.  

e.g. **HighSchool_PR** 98 or 99  

Also need to include lower scores (but sufficient for the students to try for college)

# Discussion and Conclusion

The Statistics 101 course provides a starting point for students to perform data analysis. Linear regression is widely used, but it is not a panacea for data analysis. The model assumptions need to be met in the data, as stated at the beginning of Section \ref{linear-reg}.   

For the next steps in learning statistics, we suggest reading *The Statistical Sleuth: A Course in Methods of Data Analysis* \cite{ramsey2013statistical}, which is the textbook for undergraduate-level regression analysis at Duke Statistical Science.^[<https://www2.stat.duke.edu/courses/Fall18/sta210.001/>] The book covers intermediate topics such as ANOVA (Analysis of Variance) and multiple linear regression. It also provides data files for case studies and exercises.^[<http://www.statisticalsleuth.com/>]  

For the advanced readers, we recommend the following graduate level statistics textbooks:

- *A First Course in Bayesian Statistical Methods* \cite{hoff2009first}

- *Statistical Inference* \cite{casella2021statistical}

- *Categorical Data Analysis* \cite{agresti2003categorical}

There are obviously much more high-quality statistics textbooks than the ones listed, and we selected these as a starting point.  

Write something more

# Final: Personal Remarks

Write something here  

Taipei First Girls' High School^[http://web.fg.tp.edu.tw/~tfghweb/EnglishPage/index.php] typically requires **HighSchool_PR** 99 for admission. There are some exceptions, such as recruited athletes, students with disabilities,^[<http://www.rootlaw.com.tw/LawArticle.aspx?LawID=A040080080001900-1020822>] and students under other extraordinary situations.^[<https://bit.ly/2WtRY63>]  

The Department of Electrical Engineering at National Taiwan University (NTUEE)^[https://web.ee.ntu.edu.tw/eng/index.php] typically requires
full marks (15 out of 15) in English, mathematics, and science in **College_Score** for the early admission.^[https://university.1111.com.tw/univ_depinfo9.aspx?sno=100102&mno=520101] Most students at NTUEE had a **College_Score** of 70 or higher, at the time when 75 was the max possible score. But still a significant number of students got admitted through the regular college entrance exam process in July.  

Finally, include my own scores as a datapoint for prediction.  

\textcolor{red}{Don't show the numbers until I am ready to work on this section!}

# Acknowledgments {.unnumbered}

The author would like to thank her Microsoft colleagues Smit Patel and Dylan Stout for troubleshooting GitHub issues.  

The author declares that there is no conflict of interest.  

More to add  


# Appendix {.unnumbered}

```{r include-appendix, child = 'Appendix.Rmd'}
```


# References {.unnumbered #references}