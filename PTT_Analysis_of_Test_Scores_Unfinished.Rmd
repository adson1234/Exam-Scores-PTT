---
title: "PTT Analysis of Entrance Exam Scores in Taiwan"
subtitle: "A Statistical Approach with R Code"
author: "Christine P. Chai"
date: \today
output: 
        pdf_document:
                number_sections: true
                citation_package: natbib
bibliography: references.bib
biblio-style: apalike
link-citations: yes
---

\renewcommand{\cite}{\citep}

```{r latex-cite-command, include=FALSE}
# %\let\cite\citep
# % from \citep to \cite to cite in author style, e.g. [Mule, 2008]

# % \bibliographystyle{plainnat}
# %\citep: citation in parentheses, e.g. [Mule, 2008]
# %\citet: citation as author, e.g. Mule [2008]
# %\cite: citation as author, \citet by default 
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Ongoing work since 2019.

\section*{Executive Summary}

\textcolor{red}{Write something here}

# Introduction

\textcolor{red}{Consider making the introduction statistics-oriented, because we would like to focus on the statistical methodology. Most important is how to handle a real-time application problem.}  

```{r include-intro, child = '01-Introduction.Rmd'}
```

# Background

```{r include-background, child = '02-Background.Rmd'}
```

# Data Description

```{r include-data-description, child = '03-Data-Description.Rmd'}
```

# Exploratory Data Analysis

```{r include-exploratory, child = '04-Exploratory.Rmd'}
```

# Linear Regression {#linear-reg}

```{r include-linear-reg, child = '05-Linear-Regression.Rmd'}
```

# Top Scorers: A Closer Look

```{r include-linear-reg, child = '06-Top-Scorers.Rmd'}
```

# Logistic Regression {#logit-reg}

```{r include-logit-reg, child = '07-Logistic-Regression.Rmd'}
```

# Model Validation: In-Sample Prediction {#validation}

```{r include-in-sample-00, child = '08-In-Sample-00-Foreword.Rmd'}
```

## Implementation of In-Sample Prediction {#in-sample}

```{r include-in-sample-01, child = '08-In-Sample-01-Implementation.Rmd'}
```

## Interpretation of Confusion Matrix {#interpretation}

```{r include-in-sample-02, child = '08-In-Sample-02-Confusion-Matrix.Rmd'}
```

\section*{\textcolor{red}{Unfinished below}}

\textcolor{red}{Continue to separate this enormous \texttt{.Rmd} into smaller files.}

## Breakdown by High School Entrance Exam Scores

\section*{\textcolor{red}{Unfinished below}}  

Examine the confusion matrices for each group of **HighSchool_PR**: 0-79, 80-89, 90-94, 95-99.  

Ensure that each group has a sufficiently large number of respondents.  

Total: 188 records.  

Refer to Section \ref{HighSchool-PR-80-up} for the details of this categorization.  

Create more graphs  

```{r breakdown-by-pr}
HS0to79_ind = which(data_corr$HighSchool_PR >=0 & data_corr$HighSchool_PR <= 79)
HS80to89_ind = which(data_corr$HighSchool_PR >= 80 & data_corr$HighSchool_PR <= 89)
HS90to94_ind = which(data_corr$HighSchool_PR >= 90 & data_corr$HighSchool_PR <= 94)
HS95to99_ind = which(data_corr$HighSchool_PR >= 95 & data_corr$HighSchool_PR <= 99)

print(paste("HighSchool_PR 0-79:",length(HS0to79_ind)))
print(paste("HighSchool_PR 80-89:",length(HS80to89_ind)))
print(paste("HighSchool_PR 90-94:",length(HS90to94_ind)))
print(paste("HighSchool_PR 95-99:",length(HS95to99_ind)))
```

# Model Validation: Out-of-Sample Prediction {#outsample}

```{r include-out-sample-00, child = '09-Out-Sample-00-Foreword.Rmd'}
```

## Separate Training and Testing Datasets

```{r include-out-sample-01, child = '09-Out-Sample-01-Sep-Explain.Rmd'}
```

### Implementation {#train-test-demo}

```{r include-out-sample-02, child = '09-Out-Sample-02-Sep-Implement.Rmd'}
```

### Organizing the Code for Reusability

```{r include-out-sample-03, child = '09-Out-Sample-03-Sep-Organize.Rmd'}
```

```{r header-code,include=FALSE}
data = read.csv("ptt_SENIORHIGH_data.csv")
names(data)[1] = "pttID"

missing_rows = which(data$HighSchool_PR == "-1" | data$College_Score == "-1")
data_corr = data[-missing_rows,]

data_corr$CS_65up = data_corr$College_Score >=65

model = glm(CS_65up ~ HighSchool_PR, data=data_corr, family="binomial")

print("This is a test.")
```

## Cross Validation

```{r include-out-sample-04, child = '09-Out-Sample-04-Cross-Validation.Rmd'}
```

### K-fold Cross Validation

```{r include-out-sample-05, child = '09-Out-Sample-05-K-Fold.Rmd'}
```


### Leave-one-out Cross Validation

In **leave-one-out cross validation**, each record is considered an independent subset. This is essentially setting $K$ to be the number of total records in the data, say $N$. We train the model on the $N-1$ records and test the model on the one left-out record. This allows each record to get its own prediction. The key advantage is that the results are a relatively accurate estimate of the model performance.^[<https://machinelearningmastery.com/loocv-for-evaluating-machine-learning-algorithms/>] Note that when $N$ is extremely large, the computational cost would be high because we need to perform $N$ rounds of validation with $N-1$ records each. The complexity is $O(N^2)$.  

Here is the code for leave-one-out cross validation. Since each record is predicted by all the other records in the data, no randomness is involved in creating the data split. Hence we do not have to set a random seed in the process.  

```{r leave-one-out}
nn = nrow(data_corr) # total 188 rows of data

prob_leave1out = rep(c(-1), nn)

for (ii in 1:nn) {
  data_test = data_corr[ii,] # reserve one record for testing
  data_exclude = data_corr[-ii,]

  train_leave1out = glm(CS_65up ~ HighSchool_PR, data=data_exclude, family="binomial")
  # summary(train_leave1out)
  
  test_leave1out = predict.glm(train_leave1out, data_test, type="response")
  # type="response" gives the predicted probabilities

  # Store the predicted probability to the general list
  prob_leave1out[ii] = test_leave1out
}
```

Now we summarize the predictive probabilities in a single confusion matrix. The results are exactly the same as the in-sample prediction in Section \ref{validation}, which may be a coincidence.

```{r leave-one-out-matrix}
matrix_leave1out = prob_to_matrix(data_corr, prob_leave1out)
matrix_leave1out
```

We also calculate the five metrics: accuracy, precision, recall, FPR, and FNR.  

```{r leave-one-out-results}
leave1out_results = confusion_to_measures(matrix_leave1out)
round(leave1out_results, digits=4)
```

## Comparison of Results

Table \ref{tab:out-train-test} summarizes the results of in-sample prediction and out-of-sample prediction. Separate training \& testing and k-fold cross validation are the average results of five iterations each. The accuracy is slightly above 70\%, the precision is around 68\%, and the recall is approximately 78\%. Since the outcomes are similar across each method, we are not concerned about overfitting in the logistic regression model.  

\begin{table}[ht]
    \centering
    \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    ~                              & Accuracy & Precision & Recall  & FPR     & FNR     \\ \hline
    In-Sample Prediction           & 70.74\%  & 67.29\%   & 78.26\% & 36.46\% & 21.74\% \\ \hline
    Separate Training \& Testing (Average)  & 71.28\%  & 69.64\%   & 76.59\% & 34.30\% & 23.41\% \\ \hline
    K-Fold Cross Validation (Average)       & 71.60\%  & 68.32\%   & 78.26\% & 34.79\% & 21.74\% \\ \hline
    Leave-one-out Cross Validation & 70.74\%  & 67.29\%   & 78.26\% & 36.46\% & 21.74\% \\ \hline
    \end{tabular}
    \caption{Comparison of results with in-sample and out-of-sample prediction}
    \label{tab:out-train-test}
\end{table}

This model uses **HighSchool_PR** scores to predict whether a student would get **College_Score** at least 65 or not. But the model is imperfect in prediction, just as we explained in Section \ref{interpretation}.

- The **precision** is the number of true positives divided by the predicted positives. This means among the students with good **HighSchool_PR** scores, around 68\% of them achieved **College_Score** at least 65 three years later.\footnote{The high school is three years in Taiwan (grades 10-12).} 

- The **recall** is the number of true positives divided by the actual positives. This means among the students with **College_Score** at least 65, approximately 78\% them had good **HighSchool_PR** scores three years ago.

\textcolor{red}{\Large Unfinished below}   

- The **FPR (false positive rate)** is the number of false positives divided by the actual negatives. This means among the students with **College_Score** 64 or below, about 35\% of them were originally predicted to have **College_Score** at least 65.


- The **FNR (false negative rate)** is the number of false negatives divided by the actual positives. This means among the students with **College_Score** at least 65, slightly over 20\% of them were "pleasant surprises" because we did not predict them to achieve such scores given their **HighSchool_PR**.


More interpretation here   



# Predictive Modeling

Use the logistic regression to predict new datapoints.  

e.g. **HighSchool_PR** 98 or 99  

Also need to include lower scores (but sufficient for the students to try for college)

# Discussion and Conclusion

The Statistics 101 course provides a starting point for students to perform data analysis. Linear regression is widely used, but it is not a panacea for data analysis. The model assumptions need to be met in the data, as stated at the beginning of Section \ref{linear-reg}.   

For the next steps in learning statistics, we suggest reading *The Statistical Sleuth: A Course in Methods of Data Analysis* \cite{ramsey2013statistical}, which is the textbook for undergraduate-level regression analysis at Duke Statistical Science.^[<https://www2.stat.duke.edu/courses/Fall18/sta210.001/>] The book covers intermediate topics such as ANOVA (Analysis of Variance) and multiple linear regression. It also provides data files for case studies and exercises.^[<http://www.statisticalsleuth.com/>]  

For the advanced readers, we recommend the following graduate level statistics textbooks:

- *A First Course in Bayesian Statistical Methods* \cite{hoff2009first}

- *Statistical Inference* \cite{casella2021statistical}

- *Categorical Data Analysis* \cite{agresti2003categorical}

There are obviously much more high-quality statistics textbooks than the ones listed, and we selected these as a starting point.  

Write something more

# Final: Personal Remarks

Write something here  

Taipei First Girls' High School^[http://web.fg.tp.edu.tw/~tfghweb/EnglishPage/index.php] typically requires **HighSchool_PR** 99 for admission. There are some exceptions, such as recruited athletes, students with disabilities,^[<http://www.rootlaw.com.tw/LawArticle.aspx?LawID=A040080080001900-1020822>] and students under other extraordinary situations.^[<https://bit.ly/2WtRY63>]  

The Department of Electrical Engineering at National Taiwan University (NTUEE)^[https://web.ee.ntu.edu.tw/eng/index.php] typically requires
full marks (15 out of 15) in English, mathematics, and science in **College_Score** for the early admission.^[https://university.1111.com.tw/univ_depinfo9.aspx?sno=100102&mno=520101] Most students at NTUEE had a **College_Score** of 70 or higher, at the time when 75 was the max possible score. But still a significant number of students got admitted through the regular college entrance exam process in July.  

Finally, include my own scores as a datapoint for prediction.  

\textcolor{red}{Don't show the numbers until I am ready to work on this section!}

# Acknowledgments {.unnumbered}

The author would like to thank her Microsoft colleagues Smit Patel and Dylan Stout for troubleshooting GitHub issues.  

The author declares that there is no conflict of interest.  

More to add  


# Appendix {.unnumbered}

```{r include-appendix, child = 'Appendix.Rmd'}
```


# References {.unnumbered #references}